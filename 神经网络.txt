线性神经网络
线性神经网络与感知器的主要区别在于，感知器的激活函数只能输出两种可能的值，
而线性神经网络的输出可以取任意的值,其激活函数是线性函数。
线性神经网络采用widrow-Hoff学习规则，即LMS(Least Mean Square 最小均方值) 算法来调整网络的权值和偏置

线性神经网络在结构上与感知器非常相似，只是神经元激活函数不同。在模拟训练时把原来的sign函数改为了purelin函数(y=x)

Delta学习规则
该规则也可以称为连续感知器学习规则
Delta学习规则是一种利用梯度下降法的一般性学习规则







模型收敛的条件:
1.误差达到一定值，可以接受，则认为模型收敛
2.权值的改变量比较小时
3.循环比较大的次数后,则任务收敛



BP(back propagation) 神经网络（误差反向传播法）
1.1986年由Rumelhart和McCelland为首的科学家小组提出，解决了多层神经网络的学习问题，极大的促进了神经网络的发展
2.BP神经网络也是整个人工神经网络体系中的精华，广泛应用于分类识别，逼近，回归，压缩等领域。
在实际应用中，大约80%的神经网络模型采用了BP网络或者BP网络的变化形式
灵感来源于:Detal学习规则 梯度下降法

斯坦福大学李飞飞 如何教计算机理解图片(2016年加入google)
http://open.163.com/movie/2015/3/Q/R/MAKN9A24M_MAKN9QAQR.html
https://www.ted.com/talks/fei_fei_li_how_we_re_teaching_computers_to_understand_pictures
http://www.image-net.org

http://yann.lecun.com/exdb/lenet/index.html  (乐坤，卷积神经网络之父)

隐藏层中可以描述更多的属性

激活函数:
Sigmoid函数

Tanh函数(双曲正切函数)和Softsign函数

教科书下载:http://vdisk.weibo.com/s/AcSJGKVz_XdFZ























